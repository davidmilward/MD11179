\documentclass{llncs}


\usepackage{listings}
\usepackage{csquotes}
\usepackage{color}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{zed}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}
%%\newtheorem{definition}{Definition}
 \usepackage{listings}
 \usepackage{courier}
 \lstset{
         basicstyle=\footnotesize\ttfamily, % Standardschrift
         %numbers=left,               % Ort der Zeilennummern
         numberstyle=\tiny,          % Stil der Zeilennummern
         %stepnumber=2,               % Abstand zwischen den Zeilennummern
         numbersep=5pt,              % Abstand der Nummern zum Text
         tabsize=2,                  % Groesse von Tabs
         extendedchars=true,         %
         breaklines=true,            % Zeilen werden Umgebrochen
         keywordstyle=\color{red},
    		frame=b,         
 %        keywordstyle=[1]\textbf,    % Stil der Keywords
 %        keywordstyle=[2]\textbf,    %
 %        keywordstyle=[3]\textbf,    %
 %        keywordstyle=[4]\textbf,   \sqrt{\sqrt{}} %
         stringstyle=\color{white}\ttfamily, % Farbe der String
         showspaces=false,           % Leerzeichen anzeigen ?
         showtabs=false,             % Tabs anzeigen ?
         xleftmargin=17pt,
         framexleftmargin=17pt,
         framexrightmargin=5pt,
         framexbottommargin=4pt,
         %backgroundcolor=\color{lightgray},
         showstringspaces=false      % Leerzeichen in Strings anzeigen ?        
 }
 \lstloadlanguages{
         Java
 }
%\DeclareCaptionFont{blue}{\color{blue}} 

 %\captionsetup[lstlisting]{singlelinecheck=false, labelfont={blue}, textfont={blue}}
 % \usepackage{caption}
 
\DeclareCaptionFont{white}{\color{white}}
\DeclareCaptionFormat{listing}{\colorbox[cmyk]{0.43, 0.35, 0.35,0.01}{\parbox{\textwidth}{\hspace{15pt}#1#2#3}}}
 % \captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white, singlelinecheck=false, margin=0pt, font={bf,footnotesize}}
 
    \graphicspath{{figs/}}
 


\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white, singlelinecheck=false, margin=0pt, font={bf,footnotesize}}



\begin{document} 

\title{Metadata Registry and management based on ISO11179 using Model Based Engineering}
%If Title is too long, use \titlerunning
%\titlerunning{Short Title}

%Single institute
\author{Jim Davies, David Milward \and Seyyed Shah}
%If there are too many authors, use \authorrunning
%\authorrunning{First Author et al.}
\institute{University of Oxford}
\maketitle

\begin{abstract}
n this paper we present an ISO11179 metadata registry using a data-oriented Domain Specific Modelling Language(DSML). In particular we examine how certain aspects of the ISO11179 specification can be strengthened by using a specific DSML built to handle interoperability use cases, and also how using a model based engineering framework addresses ambiguities in the standard. We examine how the DSML approach taken in this paper presents a concrete realisation of data componentisation, harmonisation, standardisation and reuse of meta-data components. We also examine how the ISO11179 based DSML can be implemented using the Eclipse Modelling Framework and made interoperable with UML In particular, we identify how Model Driven Engineering has helped in achieving the specific goals of ISO11179 via a case study.

\end{abstract}

\keywords{...}

\noindent

\section{Introduction}

ISO11179 is the ISO standard for metadata registries. Metadata registries are used in many organisations to carry out a number of functions, nearly all of them are related to the need to ensure that data is used consistently within an organization.  The need for such a toolkit has become apparent in the last 10 years or so as the amount of data available to organizations has exploded, and despite the existence of an international standard metadata registries are implemented in a variety of different ways. Since the area of Model Driven or Model Based Engineering is based on the idea of describing key abstractions about both the structure and behaviour of data it would seem a logical step to try and build a metadata registry incorporating MBE principles.  We have built a metadata registry and tested within a number of projects in the Healthcare domain. During this process we examined the strengths and weaknesses of the standard and present the results of our research in this paper. 


\section{Backgound}

\subsection{Model Based Engineering}
Model Based Engineering or Model Driven Engineering is the software engineering practise which utilises \emph{Models} as first class entities in analysing and designing software artefacts; code is generated directly from the models, updates are made directly to the models and the code is then regenerated. A situation is achieved whereby a complete round-trip is possible from the model to the code, and then from the code back to exactly the same model. Full round tripping is not always achieved in practise, and sometimes the modelling simply serves as an initial design, from which a shell is generated and the code is completed by software developers. However considerable gains in code generation and prototyping can be achieved, and these make the modelling process worthwhile.

In MBE the overall architecture of a software project is often classified using the notion of abstraction layers. Abstraction is used in many design processes, in software engineering many sub-processes lend themselves to various kinds of mathematical modelling.  In object oriented design objects are used as the main components of a program, rather than sub-routines or functions.  These objects can be \emph{abstracted} to a kind of templated object called a \emph{class}, a class will contain a blueprint for both data and methods.  Using this idea we consider the the program running, that is the interaction of different objects, to be at level M0.  At this level the program will consist of different objects interacting according original program code, which is written for the most part a collection of various \emph{classes}.  The program code, in effect the blueprint for the program, is considered to be an abstraction of the running program, and is considered to be at level M1.  A model or program at level M1 is defined by a blueprint of model, in effect a \textbf{meta-model} which exists that level M2, and likewise a \textbf{meta-model} can be defined at a higher level of abstraction.  This abstraction \emph{layering} can continue ad-infinitum, however most MBE practitioners use 4 levels, indeed the Model Driven Architecture agreed and specified by the OMG \cite{MOF242}, also known as the Meta Object Facility (MOF) currently limits itself to 4 layers, which are illustrated in Figure~\ref{fig:mbe1}

\begin{figure}[h]
\includegraphics[width=0.8\textwidth,natwidth=610,natheight=642]{Models1}
\caption{Abstraction Layers in Model Based Engineering} 
\label{fig:mbe1}
\end{figure}

We can see that UML itself sits at what is refered to as the M2 level in this architecture model. Each abstraction layer is defined so that the level \emph{below} can be seen as being an implementation of that layer; in this way the UML model is one implementation out of many possible implementations of the UML language. The UML Language itself is an implementation of the MOF meta-meta-language which resides at the M3 layer. It is possible to use UML to define other meta-models at the M2 level, one could for instance use a sub-set of UML to define just a data language at this level.

When one builds a model for a system using MBE the model is at the same level of abstraction as the program, and can be seen as different way of representing the same thing.  A Java or C\# program therefore would sit at the M1 level, and would have a direct one-to-one relationship with a UML model at that level. The idea being that by building the model in say UML one can automatically generate the code in java.

\subsubsection{Domain Specific Languages(DSL)}
The term \emph{Domain Specific Language} is used to talk about a language which has been built purely to be used within one narrow domain of concern. It is more specialized than a general purpose language, but will generally make writting program code within that narrow domain easier.  An example here would be the language \emph{Gradle} which has been built to solve the problem of managing software development projects, and uses as first class citizens the nouns and verbs of the software development process, such as \emph{clean, run, process, etc}. It allows a domain expert to write a build process from scratch without having to know how to do a lot of the detailed work in the programming language. Gradle is written in Groovy, and compiles to the JVM, however it used by software developers developing in both JVM and non-JVM languages alike.

The term DSL is a general term and covers many different types of language.  For our purposes here we consider two main aspects of software analysis and design, the first is the modelling of the domain and the second is engineering an efficient programming language to express these models.These two aspects are often merged, however the two aspects are sometimes treated separately as with the layered modelling approach taken by Latry et al~\cite{latry2006processing}. 


\subsubsection{Domain Specific Modelling Language(DSML)}

A Domain Specific Modelling Language is one that is purely targeting the problem domain, in that it describes problems and solutions in domain terms, and provides a language which domain experts can understand and implement within their domain. In this regard we are considering the domain of managing large datasets, ontologies and classification systems, and the domain experts we are considering are those who will create and edit these datasets. 

\subsubsection{Domain Specific Programming Language(DSPL)}	
A Domain Specific Programming language is concerned with how to implement a suitable language using a general purpose programming language(GPL), frameworks, aspects, etc. There are no real rules to developing a DSPL, and it maybe that developing a DSPL is simply a stage in the development of the DSL, or it may be a module within the DSL. For the most part we haven't defined a DSPL for this project, the implementation has been carried out using the Groovy language. 

\subsubsection{Platform Independent Implementation(PIM)}

**********
\subsubsection{Platform Specific Implementation(PIM)}

\subsection{ISO11179}

The ISO11179 Standard for metadata registries defines its purposes (ISO11179-1 section 0.2 General description of ISO/IEC 11179)as follows,
\newline
to promote:
\begin{itemize}
\item Standard description of data
\item Common understanding of data across organizational elements and between organizations
\item Re-use and standardization of data over time, space, and applications
\item Harmonization and standardization of data within an organization and across organizations
\item Management of the components \emph{of descriptions} of data
\item Re-use of the components \emph{of descriptions} of data.
\end{itemize}
ISO/IEC 11179 is in effect a standard for metadata-driven exchange of data in an heterogeneous environment, based on exact definitions of data. Interoperability isn't explicitly mentioned as aan aim, however these six aims/purposes are very close to being a description of a framework for interoperability for data and data components through the use of \emph{metadata}. There is no international standard which specifically addresses interoperability, although there are a number of accepted maturity models which address interoperability issues(NIEM, ECInterop) within the enterprise.  %%The MDI model framework which emerged from the Athena and Interop NoE (INTEROP, Athena) research projects have made progress in defining ways of implementing interoperability using model driven engineering concepts and ideas, and since ISO11179 is currently in use in both the Healthcare and Defence sectors we examine the core purposes of the standard to try and determine how we it achieves these purposes. %%
The standard itself is not a specification for building a physical or logical metadata registry, but rather a set of semantic principles on how data relationships should be handled. We implement an ISO11179 conformant metadata registry using Model Based Engineering principles, and examine how use of these principles have helped achieved the purposes of ISO11179. 




\subsection{Design of an ISO11179 Metadata Registry}

ISO11179-3 has a detailed account of the registry metamodel and its attributes, and sets out to be relevent to application designers, system architects, and software developers. It uses UML 2.4.1 as a modelling language to describe the main features of a conformant metadata registry, although the standard itself is quite clear in not endorsing any particular environment, database management system, database design paradigm, system development methodology, data definition language, command language, system interface, user interface, computing platform or technology required for implementation. However in ISO11179-3.5 a metamodel is used to describe the information model of a metadata registry, and again the standard is clear that this should not limit the actual implementation technology used. The UML description is split into a number of packages:
\begin{itemize}
\item Basic Package
\item Identification Metamodel
\item Designation and Definition Metamodel
\item Registration Package
\item Concepts Package (Concepts and Classification regions)
\item Binary Relations Package
\item Data Descriptions Package
\end{itemize}
Metadata items are constrained by a set of rules which are described as follows:
\begin{itemize}
\item Rule 1 : A metadata item is  \emph{identified} if has one or more identification associations each with a \emph{Scoped\_Identifier} class.
\item Rule 2 : A metadata item is  \emph{designated} if it has one or more item\_designation associations each with a \emph{Designation} class
\item Rule 3 : A metadata item is \emph{defined} if it has one or more item\_definition associations each with a \emph{Definition} class
\item Rule 4 : A metadata item is \emph{classified} if it has one or more Classification association classes, each with a concept class in a Concept\_System.
\item Rule 5 : A metadata item is  \emph{registered} if it has one or more \emph{submission} associations, each with a Submission\_record class.
\item Rule 6 :  A metadata item is  \emph{administered} if it has exactly one stewardship association with a Stewardship\_Record class - only applies where rule 7 does not apply
\item Rule 7 : A metadata item is \emph{attached} if it has exactly one attachment association with an Administered\_Item class - can only apply in cases where rule 6 does not.
\end{itemize}

The standard continues to provide a detailed account of how metadata items are related within the metadata registry, for the purposes of brevity we will not repeat them all here, but we may refer back to specific parts of the standard where required.



\section{A DSML for Data}

\subsection{ISO11179 in MBE}

In order to look at the ISO11179 standard from a modelling perspective we need to see how the current normative description and UML diagrams, which make up the ISO11179 model, fits into a MBE architecture. In FIgure~\ref{fig:mbe1} we can see that UML itself sits at what is refered to as the M2 level in this architecture model. Each abstraction layer is defined so that the level \emph{below} can be seen as being an implementation of that layer; in this way the UML model is an implementation of the UML language, which in turn is  an implementation of the MOF meta-meta-language which resides at the M3 layer. It is possible to use UML to define meta-models at the M2 level, and this is what is being done here by using UML and text to describe the ISO11179 Model in ISO11179-3. 

The model description in the ISO11179 defines aspects of the implementation, but often does not differentiate clearly between aspects of the MDR itself, and the groups of metadata which it is holding. In reference to Figure~\ref{fig:mbe1} it is not clear which items belong at M2 and which at M1levels.  For instance is it necessary to instantiate a class of \emph{Value Domain} objects within the registry, or is it sufficient to represent this aspect of a data element using other properties of a data element class.

We took the appoach that if we can define the M2 layer, then building the M1 will be straightforward using standard model based engineering techniques. This approach still leaves the implementation details as details which can be adjusted for any particular environment, we can use different code generators on different platforms to generate different implementations of a metadata registry, but still keeping to the original standard.

.....TODO......


\subsection{Language Definition}

The metamodel or language for data we describe is informed by experience with Healthcare information systems \cite{DSMCR} and by the development of an open source Metadata Registry built around similar principles. The DSML has been built to help with data curation and creation in the Healthcare domain, and as such is the result of discussion with domain experts in this sector. The reason for designing this DSML  is that we seek a meta-language to be able handle hetrogeneous metadata stored using a variety of languages. It needs to be able to capture metadata, in particular a detailed description the data is stored in relational databases, XML Schemas, XML files based on XML Schemas, Excel files and object-oriented programs. It then needs to be able to automatically transform the data into a number of simple formats. To do this each dataset at an M1 level needs to be described at the M2 level, by doing this we can build a container which can hold the metadata collected at the M1 level.

The core entities in the metamodel are as follows:
\begin{itemize}
\item DataModel
\item DataClass
\item DataItem
\item DataType
\item DataConstraint
\end{itemize}

\begin{figure}[h]
\includegraphics[width=1.0\textwidth,natwidth=610,natheight=642]{LemmaCore1}
\caption{Core Metamodel (Lemma)} 
\label{fig:lemma}
\end{figure}

This metamodel forms a language in its own right which is able to describe the structure of data, it doesn't deal with behaviour so there are few operations in this language.

The language is a language of \emph{metadata} and it will normally sit within the context of a metadata registry or similar server artefact. The core entity in our new model is the \emph{ConceptElement} which is in effect an abstract entities from which most of the other entities derive, it handles the versioning control through the use of a GUID, which has the added benfit of turning metadata into \emph{linked metadata} automatically. The ConceptElement together with the \emph{Relationship} entity is able to define relationships between any of its sub-entities. The Tag class allows any vocabulary or ontology element to be associated with any catalogue element. This we will see later on will enable the import of standard ontologies into a metadata registry built around this metamodel.

\subsubsection{DataModel}
A DataModel is a versioning and grouping mechanism for one metadata-set, it might for instance be metadata connected with a particular database, or a particular XSD Schema which is used in a particular domain, however it allows us to group and version a related set of DataClasses.  A DataModel can contain many DataElements, and many DataTypes. A DataModel contains one or more DataItems, which may be implemented as DataClasses, DataElements, DataTypes or EnumerationValues. As all DataItems are also AbstractItems, they can have Tags, which link them to entities outside that DataModel using URI's, and they can have Relationships which are two-way associations with other AbstractItems. DataConstraints are attached to each DataModel and are applicable within that DataModel.

\subsubsection{DataClass}
 A DataClass is a mechanism for grouping DataItems, which are atomic pieces of data. A concept may be represented by a class, but the DataItem is the atomic component of that class, it can't be reduced into any smaller component. A DataClass can be used as a DataItem, in that it can be contained within another DataClass, and so it can be used to provide multi-level grouping within a DataModel. A DataClass can \emph{extend} another DataClass, this \emph{inheritance} mechanism is very straightforward, it allows the child class to have all the member DataItems and DataClasses that are present in the parent. These DataItems and DataClasses are in effect references, so that if the parent class changes then these \emph{inherited} DataItems and DataClasses will be changed as well.
 
 \subsubsection{DataElement}
 A DataElement is the smallest data entity described in this langauge, it has a direct one to one relationship with a DataType, since every DataElement will have a corresponding DataType. 
 
 \subsubsection{DataType}
 A DataType is a basic type or value representation for a particular DataItem, it represents the kind of unit of the DataItem, for instance for it could be a set of values defined by a enumerations, or it could be a number represented by an integer or double DataType. The notion of DataType here is defined by Pierce~\cite{Pierce} as follows:
\textbf{A type system is a tractable synthetic method for proving the absence of certain program behaviours by classifying phrases according to the kinds of values they compute}. 

We use this modelling language to define metamodels, which are housed in the metadata registry, each metamodel being the description of a data-item or a group of data-items. In the next section we explain how this language satisfies the metamodel described in ISO11179-3.

\subsection{Language Entities}

The overall item in our language is a \emph{DataModel}, a DataModel will contain other DataItems, which in turn can be made up from a number of different entities.

We introduce an entity called a \emph{DataClass}, in order to group and classify DayaItems, a \emph{DataClass} is similar to a \emph{class} in UML, and in other languages such as Java. A DataClass can contain DataElements, and it can also contain other DataClasses. DataClasses are grouped into DataModels which represent a unitary collection of data entities which can be managed and versioned together, in practise these will correspond with current datasets such as COSD, curated datasets used for a singular purpose in a particular domain, such as Healthcare. In UML the \emph{grouping} mechanism is the \emph{class}, however within ISO11179 a mechanism of grouping on either \emph{object class} or \emph{property} is mandated, this has no meaning within the model driven world so we cannot use it here. 


We need to introduce some general sets, to model things like identifiers, names etc, hence:



At a basic level the language is dealing with AbstractItems, any of which can represent a piece of data. These \emph{AbstractItems} can form relationships with other items, so that any item in the language can have a relationship with any other item, unless contrained not to. Any item can \emph{own} or \emph{contain} any number of \emph{Tags}, which can reference other data items outside of this particular model, using a URI as its identifier.  

We need to model the basic entities in our new language:
%\begin{syntax}
 % Kind & ::= & \abstractitem \mid \datamodel \mid \dataitem \mid \dataclass \\
 % 	 & \mid & \tag \mid \dataelement  \mid \datatype \mid \enum \\
 % 	   & \mid & \enumeration \mid \primitivetype 
%\end{syntax}



\section{Implementation of the Metadata Registry}

In implementing a metadata registry based on the standard we need to separate which parts of the specification deal with a metadata registry, and which parts specify the metadata which is registered in the registry. ISO11179:3 is split into several sections, sections 1 - 4 consist of an introduction, references, terminology and conformance details, for the purposes of implementing the MDR we need the following sections:
\begin{itemize}
\item Section 5 : Structure of a Metadata Registry
\item Section 6 : Basic Package : common datatypes and classes
\item Section 7 : Identification, Designation and Definition Package
\item Section 8 : Registration Package
\item Section 9 : Concepts Package
\item Section 10 : Binary Relations Package
\item Section 11 : Data Descriptions Package
\end{itemize}

\subsection{Structure of a Metadata Registry}
The following sections provide a brief overview of our approach to building the registry using the DSML, and how it can be used to implement  the requirements given in this section of the standard.

\subsubsection{Basic Package : common datatypes and classes}



\subsubsection{Identification, Designation and Definition Package}





\subsubsection{Registration Package}

\subsubsection{Concepts Package}

\subsubsection{Binary Relations Package}

\subsubsection{Data Descriptions Package}


\section{Metadata Management}
This section gives a brief overview of the tasks which data registration authorities face, the principle problem being what data is held where, what formats are being used and how does it relate to other datasets being managed directly or indirectly. It could be that one data item has a reference to another data item managed by a different authority and the only reference is a written instruction stating that this \emph{dataitem is not the same as that dataitem}. 

The principal tasks faced by a data registration authority are given as:
\begin{itemize}
\item Creation of new datasets
\item Curation of existing datasets
\item Merging of existing datasets
\item Querying over existing datasets
\end{itemize}

The first task or use case is relatively straightforward, however there is one aspect that needs discussion. Very often datasets are developed by teams, and often using tools that are not really designed for dataset development. In the NHS we have found that many datasets are initially developed by domain experts using Excel, mostly because it is accessible and is easy to interpret at a high level. One of the biggest problems encountered here is simply co-ordination amongst the contributors. 

The next task is curation of existing datasets, once a dataset is published and is being used it's shortcomings will be noted by users who will lobby for changes. Datasets are easier to manage if they conform to the Open-Closed Principle of software engineering, first introduced by Bertram Meyer \cite{Meyer} which states that a module should be open to extension and closed to change. This means that datasets or datamodels can be extended by being added to, but that existing items should not be changed. Changing is possible, but it implies the start of a completely new DataModel, since it is very difficult to migrate existing artefacts from DataModel A to DataModel B if something has been removed or changed in A, however the addition of say another DataElement won't break existing artefacts.

The merging of datasets is another area of curation which is carried out by any registration authority and which is help by a metadata registry. The important points to note here are 1) the abiltiy to identify a particular element 2) the ability to relate it to another particular element and 3) the ability to measure the difference and decide which parts go into the merged dataset. Inevitably the mered dataset will contain back references to the originating dataitems, how easy these are to access and address is another point of note for the data curator.

The last point is the querying of data itself, although this is not really a function of a metadata registry, data querying is dependent on having data indexed in a structured manner, even if the data itself is stored in an unstructured manner. The better the index the better the search, and in many cases indexed searches on unstructured data can be fast and more effective that searches on data stored in normalized relational databases. 



\section{Results}




\section{Discussion}

\section{Related Work}

 


\newpage

\bibliographystyle{plain}

\bibliography{md11179}
%%\subsubsection{Standard Data Description}

%%The standard data description in ISO11179 is given in section1.6.1 where the idea of a data element is introduced, and with it the idea that it is composed of two parts, its conceptual part and its representational part. This section further puts forward the notion that a data element concept can be composed of two parts, an object class and a property. An object class is said to correspond with a class (in OO terms) or an entity(in ER terms). This is further illustrated with the illustration copied fro the ISO11179 documentation below in figure~\ref{fig:DEC}:

%%\begin{figure}[h]
%%\includegraphics[width=0.6\textwidth,natwidth=610,natheight=642]{DataElementConcept}
%%\caption{Data Elements and Data Element Concepts} 
%%\label{fig:DEC}
%%\end{figure}

%%The standard continues to describe the relationship between data elements and the concepts associated with them, and also puts forward the notion that a data element is produced when a data element concept is associated with a representation. The notion of \emph{value domains} is introduced, where a value domain is defined as:

%%\begin{quotation} {sets of permissible values for data} \end{quotation}

%%This section then looks in detail at ways in which the conceptual aspects of data elements and value domains are related, and during these discussions the a fundamental model of value domains is presented. Other concepts such as measurement units and enumerations are used to further define the role of the value domain within the standard. Section 1.6 discusses aspects of classification of data elements, apart from the previously introduced notions of object class and property which are part of the Data Element Concept idea. An overview of a metadata registry is introduced in section 1.7, the main feature being that it is a database for metadata built along the lines of the conceptual model provided in section 3 of the standard. Section 1.8 covers the rest of the standard, in addition there is a detailed treatment of terminological principles in the appendix.


%\subsubsection{Common understanding of Data}

%%Part 4 of the standard details how to formulate good data definitions, and data definitions are one of the key aspects to achieving a common understanding. The advice in this part of the standard can be summarised as follows: 
%%\begin{itemize}
%%\item State the essential meaning of the concept
%%\item Be precise and unambiguous
%%\item Be concise
%%\item Be able to stand alone
%%\item Be expressed without embedding rationale, functional usage, domain information, or procedural information.
%%\item Avoid circular reasoning
%%\item Use the same terminology and consistent logical structure for related definitions
%%\item Be appropriate for the type of metadata being defined.
%%\end{itemize}

%\subsubsection{Re-use and Standardization of Data over time, space and applications}

%%According to section 5 Standardization involves standardizing the descriptive data itself: characteristics, property values of characteristics, selection of signifiers, and the meaning of values.  It can occur at a variety of levels: agency, national , regional, or international. Governance is further applied by accredited standards organizations, who may well have their own standardization processes. ISO11179-5 details key aspects of naming which should be part of any naming system for data items contained in a registry, and lists a number of criteria which a conforming registry should adhere to. It doesn't prescribe any particular naming system, but rather the key qualities that a naming system should have, and which a registry should document. Part 6 details the organizational requirements for running and administering a metadata registry, however it doesn't specify how re-use or standardization of data over time, space and applications will be enhanced by using an ISO11179 conformant metadata registry. By applying a naming convention to metadata, and by enforcing a rigorous application of that naming convention we can standardise data, however there are no clear practical indications of how this is to be done in the standard.

%%\subsubsection{Harmonization and Standardization of data}

%%This follows on from the previous goals listed in the standard, and there is little doubt that having the ability to compare data elements from different classification systems will greatly help in harmonizing datasets.

%%\subsubsection{Management of the components \emph{of descriptions} of data}

%%Here the standard has changed in that the last iteration of the standard has changed the purpose from \emph'{Management of the components of data} to \emph'{Management of the components of descriptions of data}. Most computer scientists would read this as being a change from the idea of \emph{object} to \emph{class}, since an object can be seen as being a component of data, and a class as being a component of a description of data. We consider the term \emph{metadata components} or \emph{models} to be more fitting. Although the management of data components or metadata components is talked about within the standard, it is very often in the terms of the meta-model behind the standard, ideas such as \emph{arranging semantic components with a naming convention} (ISO11179-5.p6) are discussed, but with almost no reference to actual details of what a semantic component is, whether it is referring to combination of a data element and data element concept or an object running in an object oriented programming language. In our view the management models or metadata components is not really addressed by the standard, and it really needs to be.

%%\subsubsection{Re-use of the components of descriptions of data}

%%As with the previous discussion we fail to see any direct way in which the standard supports this avowed purpose except indirectly. There is no real definition on what is being referred to by descriptions of data, except in the discussions over what is metadata, when it appears that metadata is defined as being ``'descriptions of data'. This being the case it begs the question of why this purpose is using the terminology \emph{descriptions of data} instead of \emph{metadata}. 

\end{document}  